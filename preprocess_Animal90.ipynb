{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jLrn6NbZQ-zD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import os\n",
        "import cv2 \n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "import sys\n",
        "import math\n",
        "import random\n",
        "from skimage.transform import rotate, AffineTransform\n",
        "from skimage.util import random_noise\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import TensorDataset, ConcatDataset\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8nCBRoTYdle1",
        "outputId": "89be6fee-83e2-4b20-aa43-68f80256d194",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preparation"
      ],
      "metadata": {
        "id": "rQfhsRgWSGTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This class reads the data for each dataset\n",
        "class readDataset:\n",
        "    def __init__(self, num_classes, path):\n",
        "        self.height = 200\n",
        "        self.width = 200\n",
        "        self.channels = 3\n",
        "        self.path = path\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def Animal90(self):\n",
        "        path = self.path + 'name_of_the_animals.txt'\n",
        "        # extracting class names\n",
        "        with open(path) as f:\n",
        "            lines = f.readlines()\n",
        "        class_names= []\n",
        "        for i in lines:\n",
        "            class_names.append(i.strip())\n",
        "        # list which contains data\n",
        "        data = []\n",
        "        data_labels = []\n",
        "        # read path names of dataset\n",
        "        for i in range(self.num_classes) :\n",
        "            path = self.path + 'animals/' +class_names[i] \n",
        "            data_names = os.listdir(path)\n",
        "            print(\"\\n class: \",i)\n",
        "            print(\"number of train data: \",len(data_names))\n",
        "            # read whole data\n",
        "            for j in range(len(data_names)):\n",
        "                path_to_image = path + \"/\" + data_names[j]\n",
        "                image = cv2.imread(path_to_image)\n",
        "                image = cv2.resize(image, (self.height, self.width))\n",
        "                data.append(np.array(image))\n",
        "                data_labels.append(i)\n",
        "\n",
        "        # return two lists\n",
        "        data = np.array(data)\n",
        "        # encode the labels\n",
        "        data_labels = tf.keras.utils.to_categorical(np.array(data_labels), self.num_classes)\n",
        "\n",
        "        return data, data_labels\n"
      ],
      "metadata": {
        "id": "bScbFrSETP7Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/projectDataset/animal90/\"\n",
        "animal90 = readDataset(90, dataset_path)\n",
        "data, data_labels = animal90.Animal90()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bC52dilV_Oq",
        "outputId": "1b19296c-a07a-4b2d-c0f9-83ec79f7d9da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " class:  0\n",
            "number of train data:  60\n",
            "\n",
            " class:  1\n",
            "number of train data:  60\n",
            "\n",
            " class:  2\n",
            "number of train data:  60\n",
            "\n",
            " class:  3\n",
            "number of train data:  60\n",
            "\n",
            " class:  4\n",
            "number of train data:  60\n",
            "\n",
            " class:  5\n",
            "number of train data:  60\n",
            "\n",
            " class:  6\n",
            "number of train data:  60\n",
            "\n",
            " class:  7\n",
            "number of train data:  60\n",
            "\n",
            " class:  8\n",
            "number of train data:  60\n",
            "\n",
            " class:  9\n",
            "number of train data:  60\n",
            "\n",
            " class:  10\n",
            "number of train data:  60\n",
            "\n",
            " class:  11\n",
            "number of train data:  60\n",
            "\n",
            " class:  12\n",
            "number of train data:  60\n",
            "\n",
            " class:  13\n",
            "number of train data:  60\n",
            "\n",
            " class:  14\n",
            "number of train data:  60\n",
            "\n",
            " class:  15\n",
            "number of train data:  60\n",
            "\n",
            " class:  16\n",
            "number of train data:  60\n",
            "\n",
            " class:  17\n",
            "number of train data:  60\n",
            "\n",
            " class:  18\n",
            "number of train data:  60\n",
            "\n",
            " class:  19\n",
            "number of train data:  60\n",
            "\n",
            " class:  20\n",
            "number of train data:  60\n",
            "\n",
            " class:  21\n",
            "number of train data:  69\n",
            "\n",
            " class:  22\n",
            "number of train data:  60\n",
            "\n",
            " class:  23\n",
            "number of train data:  60\n",
            "\n",
            " class:  24\n",
            "number of train data:  70\n",
            "\n",
            " class:  25\n",
            "number of train data:  60\n",
            "\n",
            " class:  26\n",
            "number of train data:  60\n",
            "\n",
            " class:  27\n",
            "number of train data:  60\n",
            "\n",
            " class:  28\n",
            "number of train data:  60\n",
            "\n",
            " class:  29\n",
            "number of train data:  60\n",
            "\n",
            " class:  30\n",
            "number of train data:  60\n",
            "\n",
            " class:  31\n",
            "number of train data:  60\n",
            "\n",
            " class:  32\n",
            "number of train data:  60\n",
            "\n",
            " class:  33\n",
            "number of train data:  70\n",
            "\n",
            " class:  34\n",
            "number of train data:  60\n",
            "\n",
            " class:  35\n",
            "number of train data:  60\n",
            "\n",
            " class:  36\n",
            "number of train data:  60\n",
            "\n",
            " class:  37\n",
            "number of train data:  60\n",
            "\n",
            " class:  38\n",
            "number of train data:  60\n",
            "\n",
            " class:  39\n",
            "number of train data:  60\n",
            "\n",
            " class:  40\n",
            "number of train data:  60\n",
            "\n",
            " class:  41\n",
            "number of train data:  60\n",
            "\n",
            " class:  42\n",
            "number of train data:  60\n",
            "\n",
            " class:  43\n",
            "number of train data:  60\n",
            "\n",
            " class:  44\n",
            "number of train data:  60\n",
            "\n",
            " class:  45\n",
            "number of train data:  60\n",
            "\n",
            " class:  46\n",
            "number of train data:  60\n",
            "\n",
            " class:  47\n",
            "number of train data:  60\n",
            "\n",
            " class:  48\n",
            "number of train data:  60\n",
            "\n",
            " class:  49\n",
            "number of train data:  60\n",
            "\n",
            " class:  50\n",
            "number of train data:  60\n",
            "\n",
            " class:  51\n",
            "number of train data:  60\n",
            "\n",
            " class:  52\n",
            "number of train data:  60\n",
            "\n",
            " class:  53\n",
            "number of train data:  60\n",
            "\n",
            " class:  54\n",
            "number of train data:  60\n",
            "\n",
            " class:  55\n",
            "number of train data:  60\n",
            "\n",
            " class:  56\n",
            "number of train data:  60\n",
            "\n",
            " class:  57\n",
            "number of train data:  60\n",
            "\n",
            " class:  58\n",
            "number of train data:  60\n",
            "\n",
            " class:  59\n",
            "number of train data:  60\n",
            "\n",
            " class:  60\n",
            "number of train data:  60\n",
            "\n",
            " class:  61\n",
            "number of train data:  60\n",
            "\n",
            " class:  62\n",
            "number of train data:  60\n",
            "\n",
            " class:  63\n",
            "number of train data:  60\n",
            "\n",
            " class:  64\n",
            "number of train data:  60\n",
            "\n",
            " class:  65\n",
            "number of train data:  60\n",
            "\n",
            " class:  66\n",
            "number of train data:  60\n",
            "\n",
            " class:  67\n",
            "number of train data:  60\n",
            "\n",
            " class:  68\n",
            "number of train data:  60\n",
            "\n",
            " class:  69\n",
            "number of train data:  60\n",
            "\n",
            " class:  70\n",
            "number of train data:  60\n",
            "\n",
            " class:  71\n",
            "number of train data:  60\n",
            "\n",
            " class:  72\n",
            "number of train data:  60\n",
            "\n",
            " class:  73\n",
            "number of train data:  60\n",
            "\n",
            " class:  74\n",
            "number of train data:  60\n",
            "\n",
            " class:  75\n",
            "number of train data:  60\n",
            "\n",
            " class:  76\n",
            "number of train data:  60\n",
            "\n",
            " class:  77\n",
            "number of train data:  60\n",
            "\n",
            " class:  78\n",
            "number of train data:  60\n",
            "\n",
            " class:  79\n",
            "number of train data:  60\n",
            "\n",
            " class:  80\n",
            "number of train data:  60\n",
            "\n",
            " class:  81\n",
            "number of train data:  60\n",
            "\n",
            " class:  82\n",
            "number of train data:  60\n",
            "\n",
            " class:  83\n",
            "number of train data:  60\n",
            "\n",
            " class:  84\n",
            "number of train data:  60\n",
            "\n",
            " class:  85\n",
            "number of train data:  60\n",
            "\n",
            " class:  86\n",
            "number of train data:  60\n",
            "\n",
            " class:  87\n",
            "number of train data:  60\n",
            "\n",
            " class:  88\n",
            "number of train data:  60\n",
            "\n",
            " class:  89\n",
            "number of train data:  60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this cell is saving the train and test data in to the drive\n",
        "# comment in case\n",
        "path_save = '/content/drive/MyDrive/projectDataset/animal90/numpyFiles/'\n",
        "np.save(path_save+'data.npy', data)\n",
        "np.save(path_save+'data_labels.npy',data_labels)"
      ],
      "metadata": {
        "id": "ElTEDH_3cHQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this cell is loading the numpies from the drive and convert to torch\n",
        "\n",
        "path_save = '/content/drive/MyDrive/projectDataset/animal90/numpyFiles/'\n",
        "data = torch.tensor(np.load(path_save+'data.npy'))\n",
        "data_labels = torch.tensor(np.load(path_save+'data_labels.npy'))"
      ],
      "metadata": {
        "id": "SIVWRooPmWjk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizing the data\n",
        "# train_data = train_data/255.0\n",
        "# test_data = test_data/255.0"
      ],
      "metadata": {
        "id": "pFYtE5XTUp1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split data to train and test\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(data, \n",
        "                                                                 data_labels, \n",
        "                                                                 test_size=0.2)\n",
        "# split train to train and val\n",
        "train_data, val_data, train_labels, val_labels = train_test_split(train_data, \n",
        "                                                                 train_labels, \n",
        "                                                                 test_size=0.2)"
      ],
      "metadata": {
        "id": "H0YzKplej9q0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Augmentation in Pytorch"
      ],
      "metadata": {
        "id": "bKfdMkodjucn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataloader pytorch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "\n",
        "# create tensor dataset\n",
        "train_dataset = TensorDataset(train_data, train_labels)\n",
        "val_dataset = TensorDataset(val_data, val_labels)\n",
        "test_dataset = TensorDataset(test_data, test_labels)"
      ],
      "metadata": {
        "id": "NLqVbcTvjznx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.RandomRotation(degrees=45),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.15, 0.15)),\n",
        "    # transforms.RandomResizedCrop(size=(224, 224), scale=(0.5, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "papEtZjvjzsY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this list includes k random number within the range of train length\n",
        "train_random_list = random.sample(range(0, len(train_data)), round(0.5 * len(train_data)))\n",
        "val_random_list = random.sample(range(0, len(val_data)), round(0.5 * len(val_data)))"
      ],
      "metadata": {
        "id": "L501_SbKjzul"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply transformations to each sample in the dataset\n",
        "transformed_train = []\n",
        "cnt = 0\n",
        "for sample, label in train_dataset:\n",
        "    if cnt in train_random_list:\n",
        "      transformed_sample = transform(sample.permute(2, 0, 1))\n",
        "      # print(transformed_sample.shape)\n",
        "      transformed_train.append((transformed_sample.permute(1, 2, 0), label))\n",
        "    cnt += 1"
      ],
      "metadata": {
        "id": "DlW8G7hUjzw-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate the two datasets\n",
        "augmented_train_dataset = ConcatDataset([train_dataset, transformed_train])"
      ],
      "metadata": {
        "id": "_i4-5GxWkCI7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply transformations to each sample in the val dataset\n",
        "transformed_val = []\n",
        "cnt = 0\n",
        "for sample, label in val_dataset:\n",
        "    if cnt in val_random_list:\n",
        "      transformed_sample = transform(sample.permute(2, 0, 1))\n",
        "      # print(transformed_sample.shape)\n",
        "      transformed_val.append((transformed_sample.permute(1, 2, 0), label))\n",
        "    cnt += 1"
      ],
      "metadata": {
        "id": "pzSCi39lkCKD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate the two datasets\n",
        "augmented_val_dataset = ConcatDataset([val_dataset, transformed_val])"
      ],
      "metadata": {
        "id": "lF01rpcRkYVM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataloader \n",
        "train_loader = DataLoader(augmented_train_dataset, batch_size=128,\n",
        "                          shuffle=True, drop_last=True)\n",
        "val_loader = DataLoader(augmented_val_dataset, batch_size=128, \n",
        "                        shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, \n",
        "                         shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "Y1bfl7YakYhD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for train, label in train_loader:\n",
        "    print(train.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVE82Tp6zIXz",
        "outputId": "046bb7d8-d567-44da-fdaa-e3e04a8e17f8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 200, 200, 3])\n"
          ]
        }
      ]
    }
  ]
}